{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff2ebd2-2f93-4c3a-a1df-f95087aa7050",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопросы:\n",
      "   q_id                                              query\n",
      "0     1                                        Номер счета\n",
      "1     2                              Где узнать бик и счёт\n",
      "2     3  Мне не приходят коды для подтверждения данной ...\n",
      "3     4  Оформила рассрочку ,но уведомлений никаких не ...\n",
      "4     5  Здравствуйте, когда смогу пользоваться кредитн...\n",
      "\n",
      "База знаний (сайты):\n",
      "   web_id                                   url  kind  \\\n",
      "0       1                  https://alfabank.ru/  html   \n",
      "1       2           https://alfabank.ru/a-club/  html   \n",
      "2       3  https://alfabank.ru/a-club/ultimate/  html   \n",
      "3       4    https://alfabank.ru/actions/rules/  html   \n",
      "4       5       https://alfabank.ru/alfafuture/  html   \n",
      "\n",
      "                                               title  \\\n",
      "0  Альфа-Банк - кредитные и дебетовые карты, кред...   \n",
      "1                      А-Клуб. Деньги имеют значение   \n",
      "2                      А-Клуб. Деньги имеют значение   \n",
      "3                                   Скидки по картам   \n",
      "4  Альфа‑Будущее: Платформа для развития студенто...   \n",
      "\n",
      "                                                text  \n",
      "0  Рассчитайте выгоду\\nРасчёт калькулятора предва...  \n",
      "1  Брокерские услуги\\nОткрытие брокерского счёта ...  \n",
      "2  Хотите получить больше информации?\\nПозвоните ...  \n",
      "3  Правила проведения Акции «Альфа Пятница. Бараб...  \n",
      "4  Образование\\nМагистратуры\\nМагистратура ВШЭ\\nМ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    questions = pd.read_csv('questions_clean.csv')\n",
    "    websites = pd.read_csv('websites.csv')\n",
    "    sample_submission = pd.read_csv('sample_submission.csv')\n",
    "    print(\"Вопросы:\")\n",
    "    print(questions.head())\n",
    "    print(\"\\nБаза знаний (сайты):\")\n",
    "    print(websites.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Убедитесь, что файлы Questions.csv и Websites.csv находятся в той же папке.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883a31fd-454e-4c5c-9c0f-42f2c36900a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ВНИМАНИЕ: Файл 'train.csv' не найден. Делим 'questions.csv' случайным образом.\n",
      "Для корректного подсчета Hit@5 нужен файл с 'правильными' web_id.\n",
      "Вопросов для 'submit.csv' (train): 6577\n",
      "Вопросов для валидации (val): 400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Убедимся, что в 'query' нет пропусков\n",
    "questions['query'] = questions['query'].fillna('')\n",
    "\n",
    "# Отделим 400 вопросов на валидацию\n",
    "# (Если у вас есть ground_truth, лучше делить его, а потом джойнить вопросы)\n",
    "try:\n",
    "    # Идеальный сценарий: у вас есть файл с 'q_id' и 'web_id'\n",
    "    # Замените 'ground_truth.csv' на ваш файл с разметкой\n",
    "    ground_truth_df = pd.read_csv('train.csv') # <--- ЗАМЕНИ НА СВОЙ ФАЙЛ\n",
    "    \n",
    "    # Получаем уникальные q_id из разметки\n",
    "    all_q_ids = ground_truth_df['q_id'].unique()\n",
    "    \n",
    "    # Делим q_id\n",
    "    train_q_ids, val_q_ids = train_test_split(\n",
    "        all_q_ids, \n",
    "        test_size=400, # 400 вопросов на валидацию\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Создаем обучающую и валидационную выборки\n",
    "    questions_train = questions[questions['q_id'].isin(train_q_ids)]\n",
    "    questions_val = questions[questions['q_id'].isin(val_q_ids)]\n",
    "    \n",
    "    # Сохраняем \"правильные\" ответы для валидации\n",
    "    ground_truth_val = ground_truth_df[ground_truth_df['q_id'].isin(val_q_ids)]\n",
    "\n",
    "    print(\"Разделение на основе файла разметки (ground_truth):\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    # Если файла разметки нет, просто делим все вопросы\n",
    "    print(\"ВНИМАНИЕ: Файл 'train.csv' не найден. Делим 'questions.csv' случайным образом.\")\n",
    "    print(\"Для корректного подсчета Hit@5 нужен файл с 'правильными' web_id.\")\n",
    "    \n",
    "    questions_train, questions_val = train_test_split(\n",
    "        questions,\n",
    "        test_size=400, # или 0.1, 0.2 и т.д.\n",
    "        random_state=42 # Для воспроизводимости\n",
    "    )\n",
    "    ground_truth_val = None # Не сможем посчитать метрику\n",
    "\n",
    "print(f\"Вопросов для 'submit.csv' (train): {len(questions_train)}\")\n",
    "print(f\"Вопросов для валидации (val): {len(questions_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176311dc-f4d0-41e2-a810-b981a530343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем процесс чанкования...\n",
      "Готово. Получили 9902 чанков из 1937 документов.\n"
     ]
    }
   ],
   "source": [
    "def get_chunks(text, chunk_size=256, overlap=64):\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk_words = words[i:i + chunk_size]\n",
    "        chunks.append(\" \".join(chunk_words))\n",
    "    return chunks\n",
    "\n",
    "chunk_data = []\n",
    "\n",
    "print(\"Начинаем процесс чанкования...\")\n",
    "\n",
    "\n",
    "for index, row in websites.iterrows():\n",
    "    web_id = row['web_id']\n",
    "    title = row['title'] if pd.notna(row['title']) else ''\n",
    "    text = row['text'] if pd.notna(row['text']) else ''\n",
    "    \n",
    "    text_with_title = f\"Заголовок: {title}\\nТекст: {text}\"\n",
    "    \n",
    "    chunks = get_chunks(text_with_title, chunk_size=256, overlap=64)\n",
    "    \n",
    "    for chunk_text in chunks:\n",
    "        chunk_data.append({\n",
    "            'web_id': web_id,  # Сохраняем, какому 'web_id' принадлежит чанк\n",
    "            'text': chunk_text\n",
    "        })\n",
    "\n",
    "print(f\"Готово. Получили {len(chunk_data)} чанков из {len(websites)} документов.\")\n",
    "chunks_df = pd.DataFrame(chunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4168d9-ff9b-4a50-8d17-684e0ed399bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем Cross-encoder...\n",
      "Cross-encoder загружен.\n",
      "Начинаем векторизацию корпуса (чанков)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccc950ff968458888b87e27fdb668da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма эмбеддингов корпуса (чанков): (9902, 384)\n",
      "Начинаем векторизацию ОБУЧАЮЩИХ вопросов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55e9231a751409ca8a6dc390ff311fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма эмбеддингов ОБУЧАЮЩИХ вопросов: (6577, 384)\n",
      "Начинаем векторизацию ВАЛИДАЦИОННЫХ вопросов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7fa62deefa41bc9b23ab7347dcd22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма эмбеддингов ВАЛИДАЦИОННЫХ вопросов: (400, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') \n",
    "print(\"Загружаем Cross-encoder...\")\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "print(\"Cross-encoder загружен.\")\n",
    "\n",
    "# Векторизация корпуса (чанков) - остается без изменений\n",
    "print(\"Начинаем векторизацию корпуса (чанков)...\")\n",
    "corpus_embeddings = model.encode(\n",
    "    chunks_df['text'].tolist(), \n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(f\"Форма эмбеддингов корпуса (чанков): {corpus_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# --- ИЗМЕНЕНИЯ ЗДЕСЬ ---\n",
    "# Векторизация ОБУЧАЮЩИХ вопросов (для submit.csv)\n",
    "print(\"Начинаем векторизацию ОБУЧАЮЩИХ вопросов...\")\n",
    "query_embeddings_train = model.encode(\n",
    "    questions_train['query'].tolist(), \n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(f\"Форма эмбеддингов ОБУЧАЮЩИХ вопросов: {query_embeddings_train.shape}\")\n",
    "\n",
    "# Векторизация ВАЛИДАЦИОННЫХ вопросов (для проверки)\n",
    "print(\"Начинаем векторизацию ВАЛИДАЦИОННЫХ вопросов...\")\n",
    "query_embeddings_val = model.encode(\n",
    "    questions_val['query'].tolist(), \n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(f\"Форма эмбеддингов ВАЛИДАЦИОННЫХ вопросов: {query_embeddings_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650dfaf9-f7a2-4d6e-8ea7-2a2895a6847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс создан. Всего векторов в базе (чанков): 9902\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Нормализация корпуса (остается)\n",
    "corpus_embeddings_norm = corpus_embeddings.astype('float32')\n",
    "faiss.normalize_L2(corpus_embeddings_norm)\n",
    "\n",
    "# --- ИЗМЕНЕНИЯ ЗДЕСЬ ---\n",
    "# Нормализация ОБУЧАЮЩИХ вопросов\n",
    "query_embeddings_train_norm = query_embeddings_train.astype('float32')\n",
    "faiss.normalize_L2(query_embeddings_train_norm)\n",
    "\n",
    "# Нормализация ВАЛИДАЦИОННЫХ вопросов\n",
    "query_embeddings_val_norm = query_embeddings_val.astype('float32')\n",
    "faiss.normalize_L2(query_embeddings_val_norm)\n",
    "# ---\n",
    "\n",
    "# Создание индекса (остается)\n",
    "d = corpus_embeddings_norm.shape[1]\n",
    "index = faiss.IndexFlatIP(d)    \n",
    "index.add(corpus_embeddings_norm)\n",
    "\n",
    "print(f\"Индекс создан. Всего векторов в базе (чанков): {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a16c8-9a00-4466-8d0f-7a97d1d56903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем поиск топ-15 кандидатов для ОБУЧАЮЩИХ вопросов...\n",
      "Форма массива индексов: (6577, 15)\n",
      "Начинаем Переранжировку и Агрегацию (для submit.csv)...\n"
     ]
    }
   ],
   "source": [
    "# --- ЗАМЕНА для Ячейки 6 (Переранжировка и Агрегация) ---\n",
    "# Этот блок теперь создает submit.csv ТОЛЬКО для обучающей выборки\n",
    "\n",
    "k_candidates = 15 \n",
    "\n",
    "print(f\"Начинаем поиск топ-{k_candidates} кандидатов для ОБУЧАЮЩИХ вопросов...\")\n",
    "\n",
    "# --- ИЗМЕНЕНИЯ ЗДЕСЬ ---\n",
    "# Ищем только по ОБУЧАЮЩИМ эмбеддингам\n",
    "D, I = index.search(query_embeddings_train_norm, k_candidates) \n",
    "print(f\"Форма массива индексов: {I.shape}\")\n",
    "print(\"Начинаем Переранжировку и Агрегацию (для submit.csv)...\")\n",
    "\n",
    "# Получаем массивы с данными (чанков)\n",
    "chunk_web_ids_array = chunks_df['web_id'].values\n",
    "chunk_texts_array = chunks_df['text'].values\n",
    "\n",
    "# --- ИЗМЕНЕНИЯ ЗДЕСЬ ---\n",
    "# Берем данные ОБУЧАЮЩИХ вопросов\n",
    "q_ids_array = questions_train['q_id'].values\n",
    "query_texts_list = questions_train['query'].tolist()\n",
    "# ---\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(q_ids_array)):\n",
    "    q_id = q_ids_array[i]\n",
    "    query_text = query_texts_list[i]\n",
    "    \n",
    "    top_chunk_indices = I[i]\n",
    "    top_chunks_texts = chunk_texts_array[top_chunk_indices]\n",
    "    top_chunks_web_ids = chunk_web_ids_array[top_chunk_indices]\n",
    "\n",
    "    cross_inp = [[query_text, chunk_text] for chunk_text in top_chunks_texts]\n",
    "    cross_scores = cross_encoder.predict(cross_inp, show_progress_bar=False)\n",
    "    \n",
    "    web_id_scores = {}\n",
    "    reranked_data = list(zip(cross_scores, top_chunks_web_ids))\n",
    "    \n",
    "    for score, web_id in reranked_data:\n",
    "        if web_id not in web_id_scores:\n",
    "            web_id_scores[web_id] = 0.0\n",
    "        web_id_scores[web_id] += score\n",
    "        \n",
    "    sorted_web_ids = sorted(web_id_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_5_web_ids = [web_id for web_id, score in sorted_web_ids[:5]]\n",
    "    \n",
    "    for web_id in top_5_web_ids:\n",
    "        results_list.append({'q_id': q_id, 'web_id': web_id})\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Обработано {i+1} / {len(q_ids_array)} ОБУЧАЮЩИХ вопросов...\")\n",
    "\n",
    "# Создаем финальный DataFrame\n",
    "submit_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Сохраняем в CSV\n",
    "submit_df.to_csv('submit.csv', index=False)\n",
    "\n",
    "print(f\"\\nФайл submit.csv (с {len(q_ids_array)} вопросами) успешно создан!\")\n",
    "print(submit_df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f2ebc7-7771-4ff6-8c27-d8281d08fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Начинаем Валидацию на {len(questions_val)} вопросах ---\")\n",
    "\n",
    "k_candidates = 15\n",
    "\n",
    "print(f\"Начинаем поиск топ-{k_candidates} кандидатов для ВАЛИДАЦИОННЫХ вопросов...\")\n",
    "\n",
    "# --- ИСПОЛЬЗУЕМ ВАЛИДАЦИОННЫЕ ДАННЫЕ ---\n",
    "D_val, I_val = index.search(query_embeddings_val_norm, k_candidates) \n",
    "\n",
    "print(\"Начинаем Переранжировку и Агрегацию (для Валидации)...\")\n",
    "\n",
    "q_ids_array_val = questions_val['q_id'].values\n",
    "query_texts_list_val = questions_val['query'].tolist()\n",
    "\n",
    "# Здесь мы будем хранить наши предсказания\n",
    "# {q_id_1: [web_id_1, web_id_2, ...], q_id_2: [...]}\n",
    "val_predictions = {}\n",
    "\n",
    "for i in range(len(q_ids_array_val)):\n",
    "    q_id = q_ids_array_val[i]\n",
    "    query_text = query_texts_list_val[i]\n",
    "    \n",
    "    top_chunk_indices = I_val[i]\n",
    "    top_chunks_texts = chunk_texts_array[top_chunk_indices]\n",
    "    top_chunks_web_ids = chunk_web_ids_array[top_chunk_indices]\n",
    "\n",
    "    cross_inp = [[query_text, chunk_text] for chunk_text in top_chunks_texts]\n",
    "    cross_scores = cross_encoder.predict(cross_inp, show_progress_bar=False)\n",
    "    \n",
    "    web_id_scores = {}\n",
    "    reranked_data = list(zip(cross_scores, top_chunks_web_ids))\n",
    "    \n",
    "    for score, web_id in reranked_data:\n",
    "        if web_id not in web_id_scores:\n",
    "            web_id_scores[web_id] = 0.0\n",
    "        web_id_scores[web_id] += score\n",
    "        \n",
    "    sorted_web_ids = sorted(web_id_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Сохраняем Топ-5 предсказанных web_id\n",
    "    top_5_web_ids = [web_id for web_id, score in sorted_web_ids[:5]]\n",
    "    val_predictions[q_id] = top_5_web_ids\n",
    "\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"Обработано {i+1} / {len(q_ids_array_val)} ВАЛИДАЦИОННЫХ вопросов...\")\n",
    "\n",
    "print(\"Валидация завершена. Предсказания сохранены в 'val_predictions'.\")\n",
    "\n",
    "# --- Конец новой ячейки ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6975e2-6450-4577-9c89-84ab7b82d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- НОВАЯ ЯЧЕЙКА: Подсчет метрики Hit@5 ---\n",
    "\n",
    "def calculate_hit_at_5(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    predictions: dict {q_id: [web_id_1, ...]}\n",
    "    ground_truth: dict {q_id: {web_id_a, web_id_b, ...}}\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    total_questions = 0\n",
    "    \n",
    "    for q_id, predicted_ids in predictions.items():\n",
    "        if q_id in ground_truth:\n",
    "            total_questions += 1\n",
    "            # Множество \"правильных\" web_id для этого q_id\n",
    "            true_ids = ground_truth[q_id]\n",
    "            \n",
    "            # Проверяем, есть ли ХОТЯ БЫ ОДНО пересечение\n",
    "            if not set(predicted_ids).isdisjoint(true_ids):\n",
    "                hits += 1\n",
    "                \n",
    "    if total_questions == 0:\n",
    "        print(\"Ошибка: В 'ground_truth' нет вопросов из валидационной выборки.\")\n",
    "        return 0.0\n",
    "\n",
    "    hit_rate = hits / total_questions\n",
    "    return hit_rate\n",
    "\n",
    "# ---\n",
    "\n",
    "if ground_truth_val is not None:\n",
    "    print(\"Подготовка 'правильных' ответов для подсчета метрики...\")\n",
    "    \n",
    "    # Группируем 'правильные' ответы в словарь\n",
    "    # {q_id_1: {web_id_a, web_id_b}, q_id_2: {web_id_c}, ...}\n",
    "    ground_truth_map = ground_truth_val.groupby('q_id')['web_id'].apply(set).to_dict()\n",
    "    \n",
    "    # Считаем Hit@5\n",
    "    hit_at_5_score = calculate_hit_at_5(val_predictions, ground_truth_map)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"   ВАШ РЕЗУЛЬТАТ (Hit@5): {hit_at_5_score:.4f}\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"(Это означает, что {hit_at_5_score*100:.2f}% ваших валидационных вопросов\")\n",
    "    print(\"имеют хотя бы один 'правильный' web_id в топ-5 предсказанных.)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nНе удалось рассчитать Hit@5, так как файл с 'правильными' ответами\")\n",
    "    print(\"(например, 'train.csv' или 'ground_truth.csv') не был загружен на Шаге 1.\")\n",
    "\n",
    "# --- Конец новой ячейки ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
