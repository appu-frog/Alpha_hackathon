{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdb9f48-af7b-4722-b9a8-7a14f8a206ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопросы:\n",
      "   q_id                                              query\n",
      "0     1                                        Номер счета\n",
      "1     2                              Где узнать бик и счёт\n",
      "2     3  Мне не приходят коды для подтверждения данной ...\n",
      "3     4  Оформила рассрочку ,но уведомлений никаких не ...\n",
      "4     5  Здравствуйте, когда смогу пользоваться кредитн...\n",
      "\n",
      "База знаний (сайты):\n",
      "   web_id                                   url  kind  \\\n",
      "0       1                  https://alfabank.ru/  html   \n",
      "1       2           https://alfabank.ru/a-club/  html   \n",
      "2       3  https://alfabank.ru/a-club/ultimate/  html   \n",
      "3       4    https://alfabank.ru/actions/rules/  html   \n",
      "4       5       https://alfabank.ru/alfafuture/  html   \n",
      "\n",
      "                                               title  \\\n",
      "0  Альфа-Банк - кредитные и дебетовые карты, кред...   \n",
      "1                      А-Клуб. Деньги имеют значение   \n",
      "2                      А-Клуб. Деньги имеют значение   \n",
      "3                                   Скидки по картам   \n",
      "4  Альфа‑Будущее: Платформа для развития студенто...   \n",
      "\n",
      "                                                text  \n",
      "0  Рассчитайте выгоду\\nРасчёт калькулятора предва...  \n",
      "1  Брокерские услуги\\nОткрытие брокерского счёта ...  \n",
      "2  Хотите получить больше информации?\\nПозвоните ...  \n",
      "3  Правила проведения Акции «Альфа Пятница. Бараб...  \n",
      "4  Образование\\nМагистратуры\\nМагистратура ВШЭ\\nМ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    questions = pd.read_csv('questions_clean.csv')\n",
    "    websites = pd.read_csv('websites.csv')\n",
    "    sample_submission = pd.read_csv('sample_submission.csv')\n",
    "    print(\"Вопросы:\")\n",
    "    print(questions.head())\n",
    "    print(\"\\nБаза знаний (сайты):\")\n",
    "    print(websites.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Убедитесь, что файлы Questions.csv и Websites.csv находятся в той же папке.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342afc1a-0f09-401c-a464-7941a02faaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем процесс чанкования...\n",
      "Готово. Получили 9902 чанков из 1937 документов.\n"
     ]
    }
   ],
   "source": [
    "# Этот код вставляем после загрузки websites.csv\n",
    "\n",
    "# -- Начало нового блока (Чанкование) --\n",
    "\n",
    "def get_chunks(text, chunk_size=256, overlap=64):\n",
    "    \"\"\"Простая функция для нарезки текста на слова.\"\"\"\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk_words = words[i:i + chunk_size]\n",
    "        chunks.append(\" \".join(chunk_words))\n",
    "    return chunks\n",
    "\n",
    "chunk_data = [] # Это будет наша новая \"база знаний\"\n",
    "\n",
    "print(\"Начинаем процесс чанкования...\")\n",
    "\n",
    "# Итерируемся по каждой строке в websites\n",
    "for index, row in websites.iterrows():\n",
    "    web_id = row['web_id']\n",
    "    title = row['title'] if pd.notna(row['title']) else ''\n",
    "    text = row['text'] if pd.notna(row['text']) else ''\n",
    "    \n",
    "    # Мы добавим заголовок к каждому чанку, это часто улучшает релевантность\n",
    "    # (модель будет знать, из какого раздела этот текст)\n",
    "    text_with_title = f\"Заголовок: {title}\\nТекст: {text}\"\n",
    "    \n",
    "    chunks = get_chunks(text_with_title, chunk_size=256, overlap=64)\n",
    "    \n",
    "    for chunk_text in chunks:\n",
    "        chunk_data.append({\n",
    "            'web_id': web_id,  # Сохраняем, какому 'web_id' принадлежит чанк\n",
    "            'text': chunk_text\n",
    "        })\n",
    "\n",
    "print(f\"Готово. Получили {len(chunk_data)} чанков из {len(websites)} документов.\")\n",
    "\n",
    "# Создадим DataFrame из чанков для удобства\n",
    "# (Это необязательно, но так проще)\n",
    "chunks_df = pd.DataFrame(chunk_data)\n",
    "\n",
    "# -- Конец нового блока --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f52f3e8-48e2-44c2-8e5f-a00934c21427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    Здравствуйте, отправил деньги с т банка на аль...\n",
       "Name: query, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['query'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49282b2c-6eb1-46d7-aafa-2f9e73fa056d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>web_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1014</td>\n",
       "      <td>[394, 1223, 1270, 1929, 403]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      q_id                      web_list\n",
       "1013  1014  [394, 1223, 1270, 1929, 403]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[sample_submission['q_id'] == 1014].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4ebeb4-24fc-44f4-8575-bf43f25ef579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013    Здравствуйте, подскажите, сколько в день % нач...\n",
       "Name: query, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[questions['q_id'] == 1014]['query'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04bfe4b-3ebf-4e58-8aa4-ace3cc77dee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_id</th>\n",
       "      <th>url</th>\n",
       "      <th>kind</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>394</td>\n",
       "      <td>https://alfabank.ru/help/articles/sme/start/ot...</td>\n",
       "      <td>html</td>\n",
       "      <td>Предпринимательство без регистрации: штрафы и ...</td>\n",
       "      <td>Альфа-Банк\\nПолезное о продуктах\\nРассказываем...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     web_id                                                url  kind  \\\n",
       "393     394  https://alfabank.ru/help/articles/sme/start/ot...  html   \n",
       "\n",
       "                                                 title  \\\n",
       "393  Предпринимательство без регистрации: штрафы и ...   \n",
       "\n",
       "                                                  text  \n",
       "393  Альфа-Банк\\nПолезное о продуктах\\nРассказываем...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites[websites['web_id'] == 394].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32f62bb-6de6-4cc2-8432-8fdbb3889da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем Cross-encoder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d10b4414c34293b4053fb52ebb33bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a6fd82c28a4718805c34f642247f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7aa5b0c6a3485b954b72d7931090b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbca962559e1474aa4d9b12e1daec32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ce6f175b2b42d5ba338e8939fd3e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1369e8da66104915ae6b9d57b29d2c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ff69c7663e4ad3a4b289e29bf528c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder загружен.\n",
      "Начинаем векторизацию корпуса (чанков)... Это займет больше времени.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc29cd38a0e4131952b4f05eff6cdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем векторизацию вопросов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d475993855224716951ef8e98d614e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма эмбеддингов корпуса (чанков): (9902, 384)\n",
      "Форма эмбеддингов вопросов: (6977, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "# 1. Загружаем модель\n",
    "# 'paraphrase-multilingual-MiniLM-L12-v2' - хорошая, быстрая модель\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') \n",
    "\n",
    "# Загружаем cross-encoder\n",
    "# 'mrm8488/mBERT-v2-msmarco-mMiniLMv2-L12-H384-pt' - хорошая\n",
    "# многоязычная модель, обученная на задачах поиска (msmarco)\n",
    "print(\"Загружаем Cross-encoder...\")\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "print(\"Cross-encoder загружен.\")\n",
    "# 2. Векторизуем базу знаний (сайты)\n",
    "# Убедимся, что нет пропусков (NaN), иначе эмбеддер выдаст ошибку\n",
    "print(\"Начинаем векторизацию корпуса (чанков)... Это займет больше времени.\")\n",
    "# Передаем список текстов из наших чанков\n",
    "corpus_embeddings = model.encode(\n",
    "    chunks_df['text'].tolist(), \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Векторизация вопросов (этот блок остается БЕЗ ИЗМЕНЕНИЙ):\n",
    "questions['query'] = questions['query'].fillna('')\n",
    "print(\"Начинаем векторизацию вопросов...\")\n",
    "query_embeddings = model.encode(\n",
    "    questions['query'].tolist(), \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"Форма эмбеддингов корпуса (чанков): {corpus_embeddings.shape}\")\n",
    "print(f\"Форма эмбеддингов вопросов: {query_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e285d647-3ed5-459f-8589-b6d7f5f64f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс создан. Всего векторов в базе (чанков): 9902\n"
     ]
    }
   ],
   "source": [
    "# Этот код остается таким же, он просто будет работать с эмбеддингами чанков\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "corpus_embeddings = corpus_embeddings.astype('float32')\n",
    "query_embeddings = query_embeddings.astype('float32')\n",
    "\n",
    "faiss.normalize_L2(corpus_embeddings)\n",
    "faiss.normalize_L2(query_embeddings)\n",
    "\n",
    "d = corpus_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)    \n",
    "\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "print(f\"Индекс создан. Всего векторов в базе (чанков): {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33280b37-e507-4088-a1b9-f085fe37f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс создан. Всего векторов в базе (чанков): 9902\n"
     ]
    }
   ],
   "source": [
    "# Этот код остается таким же, он просто будет работать с эмбеддингами чанков\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "corpus_embeddings = corpus_embeddings.astype('float32')\n",
    "query_embeddings = query_embeddings.astype('float32')\n",
    "\n",
    "faiss.normalize_L2(corpus_embeddings)\n",
    "faiss.normalize_L2(query_embeddings)\n",
    "\n",
    "d = corpus_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)    \n",
    "\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "print(f\"Индекс создан. Всего векторов в базе (чанков): {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed986b3-94f2-4eaf-98db-7b4933006c7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем поиск топ-5 кандидатов для каждого вопроса...\n",
      "Форма массива индексов: (6977, 5)\n",
      "Начинаем Переранжировку и Агрегацию...\n",
      "Обработано 100 / 6977 вопросов...\n",
      "Обработано 200 / 6977 вопросов...\n",
      "Обработано 300 / 6977 вопросов...\n",
      "Обработано 400 / 6977 вопросов...\n",
      "Обработано 500 / 6977 вопросов...\n",
      "Обработано 600 / 6977 вопросов...\n",
      "Обработано 700 / 6977 вопросов...\n",
      "Обработано 800 / 6977 вопросов...\n",
      "Обработано 900 / 6977 вопросов...\n",
      "Обработано 1000 / 6977 вопросов...\n",
      "Обработано 1100 / 6977 вопросов...\n",
      "Обработано 1200 / 6977 вопросов...\n",
      "Обработано 1300 / 6977 вопросов...\n",
      "Обработано 1400 / 6977 вопросов...\n",
      "Обработано 1500 / 6977 вопросов...\n",
      "Обработано 1600 / 6977 вопросов...\n",
      "Обработано 1700 / 6977 вопросов...\n",
      "Обработано 1800 / 6977 вопросов...\n",
      "Обработано 1900 / 6977 вопросов...\n",
      "Обработано 2000 / 6977 вопросов...\n",
      "Обработано 2100 / 6977 вопросов...\n",
      "Обработано 2200 / 6977 вопросов...\n",
      "Обработано 2300 / 6977 вопросов...\n",
      "Обработано 2400 / 6977 вопросов...\n",
      "Обработано 2500 / 6977 вопросов...\n",
      "Обработано 2600 / 6977 вопросов...\n",
      "Обработано 2700 / 6977 вопросов...\n",
      "Обработано 2800 / 6977 вопросов...\n",
      "Обработано 2900 / 6977 вопросов...\n",
      "Обработано 3000 / 6977 вопросов...\n",
      "Обработано 3100 / 6977 вопросов...\n",
      "Обработано 3200 / 6977 вопросов...\n",
      "Обработано 3300 / 6977 вопросов...\n",
      "Обработано 3400 / 6977 вопросов...\n",
      "Обработано 3500 / 6977 вопросов...\n",
      "Обработано 3600 / 6977 вопросов...\n",
      "Обработано 3700 / 6977 вопросов...\n",
      "Обработано 3800 / 6977 вопросов...\n",
      "Обработано 3900 / 6977 вопросов...\n",
      "Обработано 4000 / 6977 вопросов...\n",
      "Обработано 4100 / 6977 вопросов...\n",
      "Обработано 4200 / 6977 вопросов...\n",
      "Обработано 4300 / 6977 вопросов...\n",
      "Обработано 4400 / 6977 вопросов...\n",
      "Обработано 4500 / 6977 вопросов...\n",
      "Обработано 4600 / 6977 вопросов...\n",
      "Обработано 4700 / 6977 вопросов...\n",
      "Обработано 4800 / 6977 вопросов...\n",
      "Обработано 4900 / 6977 вопросов...\n",
      "Обработано 5000 / 6977 вопросов...\n",
      "Обработано 5100 / 6977 вопросов...\n",
      "Обработано 5200 / 6977 вопросов...\n",
      "Обработано 5300 / 6977 вопросов...\n",
      "Обработано 5400 / 6977 вопросов...\n",
      "Обработано 5500 / 6977 вопросов...\n",
      "Обработано 5600 / 6977 вопросов...\n",
      "Обработано 5700 / 6977 вопросов...\n",
      "Обработано 5800 / 6977 вопросов...\n",
      "Обработано 5900 / 6977 вопросов...\n",
      "Обработано 6000 / 6977 вопросов...\n",
      "Обработано 6100 / 6977 вопросов...\n",
      "Обработано 6200 / 6977 вопросов...\n",
      "Обработано 6300 / 6977 вопросов...\n",
      "Обработано 6400 / 6977 вопросов...\n",
      "Обработано 6500 / 6977 вопросов...\n",
      "Обработано 6600 / 6977 вопросов...\n",
      "Обработано 6700 / 6977 вопросов...\n",
      "Обработано 6800 / 6977 вопросов...\n",
      "Обработано 6900 / 6977 вопросов...\n",
      "\n",
      "Файл submit.csv (с Cross-encoder'ом) успешно создан!\n",
      "   q_id  web_id\n",
      "0     1     372\n",
      "1     1     334\n",
      "2     1    1721\n",
      "3     1    1159\n",
      "4     1     741\n",
      "5     2     372\n",
      "6     2       1\n",
      "7     2      25\n",
      "8     2     741\n",
      "9     2     699\n"
     ]
    }
   ],
   "source": [
    "# --- НОВЫЙ Шаг 5 (Переранжировка и Агрегация) ---\n",
    "k_candidates = 5  # Ищем 50 лучших чанков-кандидатов\n",
    "\n",
    "print(f\"Начинаем поиск топ-{k_candidates} кандидатов для каждого вопроса...\")\n",
    "# I - это индексы (порядковые номера) чанков из chunks_df\n",
    "D, I = index.search(query_embeddings, k_candidates)\n",
    "\n",
    "print(f\"Форма массива индексов: {I.shape}\")\n",
    "print(\"Начинаем Переранжировку и Агрегацию...\")\n",
    "\n",
    "# Получаем массивы с данными\n",
    "chunk_web_ids_array = chunks_df['web_id'].values\n",
    "chunk_texts_array = chunks_df['text'].values\n",
    "q_ids_array = questions['q_id'].values\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Используем .tolist() для вопросов, это немного ускорит доступ в цикле\n",
    "query_texts_list = questions['query'].tolist()\n",
    "\n",
    "# I - это наши топ-50 индексов чанков из faiss (Шаг 4)\n",
    "\n",
    "for i in range(len(q_ids_array)):\n",
    "    q_id = q_ids_array[i]\n",
    "    query_text = query_texts_list[i]\n",
    "    \n",
    "    # 1. Получаем 50 чанков-кандидатов\n",
    "    top_chunk_indices = I[i]\n",
    "    top_chunks_texts = chunk_texts_array[top_chunk_indices]\n",
    "    top_chunks_web_ids = chunk_web_ids_array[top_chunk_indices]\n",
    "\n",
    "    # 2. Создаем пары [вопрос, чанк] для Cross-encoder'а\n",
    "    cross_inp = [[query_text, chunk_text] for chunk_text in top_chunks_texts]\n",
    "    \n",
    "    # 3. Получаем оценки (scores) от Cross-encoder'а\n",
    "    # show_progress_bar=False, чтобы не засорять вывод\n",
    "    cross_scores = cross_encoder.predict(cross_inp, show_progress_bar=False)\n",
    "    \n",
    "    # 4. Агрегация оценок (лучше, чем голосование)\n",
    "    # Мы будем не просто считать, а СУММИРОВАТЬ оценки\n",
    "    web_id_scores = {}\n",
    "    \n",
    "    # Собираем данные (оценка, web_id)\n",
    "    reranked_data = list(zip(cross_scores, top_chunks_web_ids))\n",
    "    \n",
    "    for score, web_id in reranked_data:\n",
    "        if web_id not in web_id_scores:\n",
    "            web_id_scores[web_id] = 0.0\n",
    "        # Суммируем \"силу\" релевантности\n",
    "        web_id_scores[web_id] += score\n",
    "        \n",
    "    # 5. Сортируем web_id по их суммарной оценке\n",
    "    sorted_web_ids = sorted(web_id_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # 6. Берем топ-5 web_id\n",
    "    top_5_web_ids = [web_id for web_id, score in sorted_web_ids[:5]]\n",
    "    \n",
    "    # 7. Добавляем в список для submit\n",
    "    for web_id in top_5_web_ids:\n",
    "        results_list.append({'q_id': q_id, 'web_id': web_id})\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Обработано {i+1} / {len(q_ids_array)} вопросов...\")\n",
    "\n",
    "# Создаем финальный DataFrame\n",
    "submit_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Сохраняем в CSV\n",
    "submit_df.to_csv('submit.csv', index=False)\n",
    "\n",
    "print(\"\\nФайл submit.csv (с Cross-encoder'ом) успешно создан!\")\n",
    "print(submit_df.head(10))\n",
    "\n",
    "# --- Конец НОВОГО Шага 5 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "528e8cf0-4fa5-40b0-bf50-2e749782d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поисковый запрос: 'Как получить кредитную карту?'\n",
      "\n",
      "Cross-encoder оценивает 50 кандидатов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2889ca6a44a44397b9204252b77a18f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5 лучших ЧАНКОВ (по оценке Cross-encoder'а): ---\n",
      "Место #1 (Чанк): web_id=1587, Оценка=8.7019\n",
      "  Текст: 'Заголовок: Как получить кредитную карту Текст: На сайте. Выберите подходящую карту, заполните анкету и дождитесь одобрения банка. Пластиковую карту доставим в отделение, которое вы указали в анкете, или курьером. • В мобильном приложении или Альфа-Он...'\n",
      "\n",
      "Место #2 (Чанк): web_id=921, Оценка=8.4769\n",
      "  Текст: 'точках наших партнёров (в билайн, Мегафон, М-Видео и не только). Как начать пользоваться кредитной картой? Получите карту с помощью доставки или в офисе, подпишите договор и активируйте карту. Сделать это можно в приложении или Альфа‑Онлайн: выберите...'\n",
      "\n",
      "Место #3 (Чанк): web_id=1033, Оценка=8.4611\n",
      "  Текст: 'Заголовок: Как сделать чтобы одобрили кредитную карту – Как повысить вероятность одобрения кредитки – Блог \"Альфа-Банка\" Текст: Кредитная карта — полезный и удобный инструмент, с помощью которого можно осуществлять безналичные расчёты в магазинах, ре...'\n",
      "\n",
      "Место #4 (Чанк): web_id=935, Оценка=8.4393\n",
      "  Текст: 'покупок. Кэшбэк действует на любые суммы Подумайте, как и где планируете использовать кредитную карту. Мы найдём для вас оптимальный вариант и оформим кредитку без лишних справок в день обращения Кредитный лимит и ставка определяются индивидуально. В...'\n",
      "\n",
      "Место #5 (Чанк): web_id=165, Оценка=8.4079\n",
      "  Текст: 'так и в торговых точках наших партнёров (билайн, Мегафон, М.Видео и не только). Как начать пользоваться кредитной картой? Получите карту с помощью доставки (нужно заранее согласовать день и время) или в офисе банка, подпишите договор и активируйте ка...'\n",
      "\n",
      "\n",
      "--- 5 лучших web_id (по сумме оценок): ---\n",
      "Место #1 (Документ): web_id = 1041 (Сумма оценок: 16.0396)\n",
      "Место #2 (Документ): web_id = 1029 (Сумма оценок: 15.6977)\n",
      "Место #3 (Документ): web_id = 1704 (Сумма оценок: 15.4609)\n",
      "Место #4 (Документ): web_id = 870 (Сумма оценок: 15.3569)\n",
      "Место #5 (Документ): web_id = 1587 (Сумма оценок: 8.7019)\n"
     ]
    }
   ],
   "source": [
    "# --- Начало блока для проверки ---\n",
    "\n",
    "# Убедитесь, что эти переменные доступны в вашей сессии:\n",
    "# model - наша SentenceTransformer модель\n",
    "# index - наш faiss-индекс\n",
    "# chunks_df - DataFrame с чанками и их web_id\n",
    "\n",
    "# --- НОВАЯ функция check_my_question ---\n",
    "\n",
    "# Убедитесь, что 'model', 'cross_encoder', 'index' и 'chunks_df' доступны\n",
    "\n",
    "def check_my_question_RERANKED(query_text, k=5):\n",
    "    print(f\"Поисковый запрос: '{query_text}'\\n\")\n",
    "    \n",
    "    # 1. Векторизуем ОДИН наш вопрос (Bi-encoder)\n",
    "    query_vector = model.encode([query_text]).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    \n",
    "    # 2. Ищем в индексе (faiss) 50 лучших чанков-кандидатов\n",
    "    k_candidates = 50 \n",
    "    D, I = index.search(query_vector, k_candidates)\n",
    "    \n",
    "    top_chunk_indices = I[0]\n",
    "    \n",
    "    chunk_web_ids_array = chunks_df['web_id'].values\n",
    "    chunk_texts_array = chunks_df['text'].values\n",
    "    \n",
    "    # 3. Готовим данные для Cross-encoder'а\n",
    "    top_chunks_texts = chunk_texts_array[top_chunk_indices]\n",
    "    top_chunks_web_ids = chunk_web_ids_array[top_chunk_indices]\n",
    "    \n",
    "    cross_inp = [[query_text, chunk_text] for chunk_text in top_chunks_texts]\n",
    "    \n",
    "    # 4. Получаем оценки (Scores)\n",
    "    print(\"Cross-encoder оценивает 50 кандидатов...\")\n",
    "    cross_scores = cross_encoder.predict(cross_inp, show_progress_bar=True)\n",
    "    \n",
    "    # 5. Собираем данные (оценка, web_id, текст чанка)\n",
    "    reranked_data = []\n",
    "    for score, web_id, text in zip(cross_scores, top_chunks_web_ids, top_chunks_texts):\n",
    "        reranked_data.append({\n",
    "            'score': score,\n",
    "            'web_id': web_id,\n",
    "            'text': text\n",
    "        })\n",
    "        \n",
    "    # Сортируем чанки по оценке\n",
    "    reranked_data = sorted(reranked_data, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(\"\\n--- 5 лучших ЧАНКОВ (по оценке Cross-encoder'а): ---\")\n",
    "    for i in range(5):\n",
    "        item = reranked_data[i]\n",
    "        print(f\"Место #{i+1} (Чанк): web_id={item['web_id']}, Оценка={item['score']:.4f}\")\n",
    "        print(f\"  Текст: '{item['text'][:250]}...'\\n\")\n",
    "\n",
    "    # 6. Агрегация оценок (как в пакетном режиме)\n",
    "    web_id_scores = {}\n",
    "    for item in reranked_data:\n",
    "        if item['web_id'] not in web_id_scores:\n",
    "            web_id_scores[item['web_id']] = 0.0\n",
    "        web_id_scores[item['web_id']] += item['score']\n",
    "        \n",
    "    # 7. Сортируем web_id по их суммарной оценке\n",
    "    sorted_web_ids = sorted(web_id_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n--- {k} лучших web_id (по сумме оценок): ---\")\n",
    "    \n",
    "    for i in range(k):\n",
    "        web_id, total_score = sorted_web_ids[i]\n",
    "        print(f\"Место #{i+1} (Документ): web_id = {web_id} (Сумма оценок: {total_score:.4f})\")\n",
    "\n",
    "# --- Конец НОВОЙ функции ---\n",
    "\n",
    "# --- ПРИМЕР ИСПОЛЬЗОВАНИЯ ---\n",
    "# (Вызовите, когда все будет готово)\n",
    "check_my_question_RERANKED(\"Как получить кредитную карту?\", k=5)\n",
    "\n",
    "#check_my_question(\"Как получить кредитную карту?\", k=5)\n",
    "#check_my_question(\"Сколько стоит обслуживание Альфа-Карты?\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf383e-54b6-4934-ab96-7af04156078a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
